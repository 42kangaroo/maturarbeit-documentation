%! suppress = UnresolvedReference
%! suppress = MissingImport
\chapter{Formal Languages}\label{ch:formal-languages}


\section{Definitions}\label{sec:definition}

In informatics, we often get an input as a string of characters and want to compute some function on it.
Complexity theory mostly focuses on decision problems which ask whether some input fulfils some given property.
To formalize this, there is the concept of formal languages.
The following definitions are taken from the lecture Theory of Computer Science~\cite{theory-cs}.
For the mathematical background, refer to \cref{ch:mathematical-background}.

\begin{define}[Alphabet]
    An alphabet $\Sigma$ is a finite set of symbols.
\end{define}

\begin{define}[Word]
    A word $w$ over some alphabet $\Sigma$ is a finite sequence of symbols from $\Sigma$.
    We denote $\varepsilon$ as the empty word, $\Sigma^*$ as the set of all words over $\Sigma$, $xy$ as the concatenation of the two words $x$ and $y$, $x^{n}$ as the concatenation of $x$ with itself $n$ times, and $|x|$ as the number of symbols in $x$.
\end{define}

\begin{define}[Formal language]
    A formal language is a set of words over some alphabet $\Sigma$, or equivalently a subset of $\Sigma^*$.
\end{define}

For any computational decision problem, we can reformulate it as the problem of deciding if the input word is contained in the formal language consisting of all words which have the required property.


\section{Chomsky Hierarchy}\label{sec:chromsky-hierarchy}

One of the multiple ways to categorize formal languages was invented by Avram Noam Chomsky, a modern linguist, in \cite{Chomsky1959}.
It is based on the complexity of defining the language using formal grammars, which are a finite representation of formal languages (which can be infinite in the general case).

\subsection{Grammars}\label{subsec:grammars}

A grammar can informally be seen as a set of rules telling us how to generate all words in a language.

\begin{define}[Grammar]
    A grammar is a 4-tuple $\langle V, \Sigma, R, S \rangle$ consisting of
    \begin{itemize}
        \item[$V$:] The set of non-terminal symbols.
        \item[$\Sigma$:] The alphabet of terminal symbols.
        All words generated by the grammar are in $\Sigma^{*}$.
        \item[$R$:] The set of rules of the form $a \to b$ with $a$ and $b$ being words over the alphabet consisting of the union of $V$ and $\Sigma$.
        Any rule in $R$ must have at least one symbol from $V$ on its left-hand side.
        \item[$S$:] The start symbol from the set $V$.
    \end{itemize}
\end{define}

The non-terminal symbols in $V$ are symbols that are not in $\Sigma$ and exist for the purpose of steering the process of word generation.
No non-terminal symbols appear in any of the words generated by the grammar.

To generate the words, there is the concept of derivations.
\begin{define}[Derivation]
    First, one derivation step is defined:

    We say that $u'$ can be derived directly from $u$ if
    \begin{itemize}
        \setlength\itemsep{0.15em}
        \item $u$ is of the form $xyz$ and $u'$ is of the form $xy'z$ for some words $x, y, y', z$ consisting of symbols in $\Sigma$ and $V$.
        \item there exists a rule $y \to y'$ in $R$.
    \end{itemize}

    We say that a word is in the \emph{generated language} of a grammar if it consists only of symbols in $\Sigma$ and can be derived in a finite number of steps from $S$.
\end{define}

\begin{exmp}
    Consider the grammar $\langle \{S\}, \{a, b\}, R, S \rangle$ with
    \[
        R = \begin{Bmatrix*}[l]
                S \to aSb,
                &S \to \varepsilon
        \end{Bmatrix*}
    \]
    The generated language of this grammar is $\{\varepsilon, ab, aabb, \dots\} = \{a^{n}b^{n} \mid n \in \mathbb{N}_0\}$.
\end{exmp}

Now that we have a tool to describe some infinite languages using a finite description, we can further differentiate the complexity of a language by the minimum required complexity of the rules in any formal grammar describing that language.
In the main section, only the context-sensitive languages are presented, as they are important for later chapters.
In \cref{sec:formal-languages-app}, explanations for regular languages (\cref{subsec:regular-languages}), context-free languages (\cref{subsec:context-free-languages}), and recursive languages (\cref{subsec:recursive-languages}) are provided.

\subsection{Context-Sensitive Languages}\label{subsec:context-sensitive-languages}

We can define the most significant class of languages for this document  by multiple equivalent restrictions on the grammars.

One restriction is that all rules have to be of the form $\alpha\beta\gamma \to \alpha\varphi\gamma$ with $\alpha, \gamma$ being words over the union of $\Sigma$ and $V$, $\beta \in V$ and $\varphi$ being a nonempty word over $\Sigma \cup V$.
This means that only the non-terminal symbol is allowed to change.
Additionally, if $S$ is the start symbol and never occurs on the right-hand side of any rule, we may include the exception $S \to \varepsilon$.

Equivalently, we can require that for any rule $u \to v$ we have $|u| \leq |v|$ as shown in \cite{Parkes2002}.
This means that applying any rule makes the result longer.
Again, we also allow the exception $S \to \varepsilon$ if $S$ does not occur on the right-hand side of any rule in $R$.
These grammars are called noncontracting.

\begin{exmp}
    Consider the grammar $\langle \{S, B\}, \{a, b, c\}, R, S \rangle$ with
    \[
        R = \begin{Bmatrix*}[l]
                S \to abc, &S \to aSBc, \\
                cB \to Bc, &bB \to bb
        \end{Bmatrix*}
    \]
    It generates the language $a^{n}b^{n}c^{n}$ for $n \in \mathbb{N}_{1}$ and is noncontracting.
\end{exmp}

The last restriction, the one that is most useful for proofs, is the Kuroda normal form presented in~\cite{Pettorossi2022}, where all rules have one of the following structures:
\begin{itemize}
    \setlength\itemsep{0.15em}
    \item $A \to BC$
    \item $AB \to CB$
    \item $A \to a$
    \item $S \to \varepsilon$ if $S$ is the start symbol and does not occur on any right-hand side of a rule.
\end{itemize}
where $A, B, C, S \in V$ and $a \in \Sigma$.

The corresponding formalism for these languages is the linearly bounded nondeterministic Turing machine, which can only write on the tape cells that contained the input word in the beginning.
This and an equivalent extension of second-order logic are proven in~\cref{subsec:des-context-sensitive-languages}.
