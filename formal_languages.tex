%! suppress = UnresolvedReference
%! suppress = MissingImport
\chapter{Formal Languages}\label{ch:formal-languages}


\section{Definition}\label{sec:definition}

In informatics, we often get an input as a string of characters, and want to compute some function on it.
In complexity Theory, we mostly focus on decision problems where we only want to find out if some input fulfils some given property.
To formalize this, there is the concept of formal languages.
The following definitions are taken from the lecture Theory of Computer Science~\cite{theory-cs}.
For the mathematical background, refer to \autoref{ch:mathematical-background}.

\begin{define}[Alphabet]
    An alphabet $\Sigma$ is a finite set of symbols
\end{define}

\begin{define}[Word]
    A word over some alphabet $\Sigma$ is finite sequence of symbols from $\Sigma$.
    We denote $\varepsilon$ as the empty word, $\Sigma^*$ as the set of all words over $\Sigma$ and $|w|$ as the number of symbols in $w$.
\end{define}

The concatenation of two words or symbol is written after each other, examples are $ab$ and $\Sigma^*a\Sigma^*$ (the set of all words containing at least one $a$).

\begin{define}[Formal Language]
    A formal language is a set of words over some alphabet $\Sigma$, that is a subset of $\Sigma^*$
\end{define}

For any computational decision problem, we can then reformulate it as the problem of deciding if the input word is contained in the formal language consisting of all words which have the required property.


\section{Chomsky Hierarchy}\label{sec:chromsky-hierarchy}

One of the multiple ways to categorize formal languages was invented by Avram Noam Chomsky, a modern linguist.
It is based on the complexity of defining the language in some finite way, namely using grammars, but other formalisms are equivalent.

\subsection{Grammars}\label{subsec:grammars}

A grammar can informally be seen as a set of rules telling us how to generate all words in a language.

\begin{define}[Grammar]
    A grammar is a 4-tuple $\langle V, \Sigma, R, S \rangle$ consisting of
    \begin{itemize}
        \item[$V$] The set of non-terminal symbols
        \item[$\Sigma$] The set of terminal symbols
        \item[$R$] A set of rules, formally over $(V \cup \Sigma)^{*}V(V \cup \Sigma)^{*} \times (V \cup \Sigma)^{*}$
        \item[$S$] The start symbol from the set $V$
    \end{itemize}
\end{define}

The non-terminal symbols are symbols that are not in the end alphabet $\Sigma$ and exist for the purpose of steering the process of word generation.
Further, the rules dictate that there must be at least one non-terminal symbol on the left-hand side of the production rule, as $(V \cup \Sigma)^*$ contains all words consisting of symbols from $V$ and $\Sigma$, and thus $(V \cup \Sigma)^{*}V(V \cup \Sigma)^{*}$ is the language of all words containing at least one non-terminal symbol.
We normally write rules in the form $a \to b$ instead of $\langle a, b \rangle$.

To generate the words, we have the concept of derivations.
\begin{define}[Derivation]
    First, we can define one derivation step.

    We say $u'$ can be derived from $u$ if
    \begin{itemize}
        \setlength\itemsep{0.2em}
        \item $u$ is of the form $xyz$ for some words $x, y, z \in (V \cup \Sigma)^*$ and $u'$ is of the form $xy'z$
        \item there exists a rule $y \to y'$ in $R$
    \end{itemize}

    We say that a word is in the \emph{generated language} of a grammar if it can be derived in a finite number of steps from $S$.
\end{define}

\begin{exmp}
    Consider the grammar $\langle \{S\}, \{a, b\}, R, S \rangle$ with
    \[
        R = \begin{Bmatrix*}[l]
                S \to aSb,
                &S \to \varepsilon
        \end{Bmatrix*}
    \]
    The generated language for this grammar is $\{\varepsilon, ab, aabb, \dots\} = \{a^{n}b^{n} \mid n \in \mathbb{N}_0\}$
\end{exmp}

Now that we have a tool to describe some infinite languages using a finite description, we can further differentiate the complexity of a language by the minimum required complexity of the rules in any grammar that describes the language.
In the main section, we will only present the context-sensitive languages as they are important for the personal contribution.
In the context appendix explanations for regular languages (\cref{subsec:regular-languages}), context-free languages (\cref{subsec:context-free-languages}) and recursive languages (\cref{subsec:recursive-languages}) are provided.

\subsection{Context-Sensitive Languages}\label{subsec:context-sensitive-languages}

The most important category of languages for this work have multiple restrictions on the grammars which produce the same set.

One restriction is that all rules are of the form $\alpha\beta\gamma \to \alpha\varphi\gamma$ with $\alpha, \gamma \in (\Sigma \cup V)^{*}$, $\beta \in V$ and $\varphi \in (\Sigma \cup V)^{+}$.
Additionally, if $S$ is the start variable and never occurs on the right-hand side of any rule, we may include $S \to \varepsilon$.

Equivalently, we can have all grammars with $|u| \leq |v|$ for any rule $u \to v$, in addition to the special case with the start variable mentioned above.
These grammars are called noncontracting.

The last, most useful form for proofs is the Kuroda normal form~\cite{Pettorossi2022}, where all rules have one of the following forms:
\begin{itemize}
    \setlength\itemsep{0.2em}
    \item $A \to BC$
    \item $AB \to CB$
    \item $A \to a$
    \item $S \to \varepsilon$ if $S$ is the start symbol and does not occur on any right-hand side
\end{itemize}
where $A, B, C, S \in V$ and $a \in \Sigma$.

\begin{exmp}
    Consider the grammar $\langle \{S, B\}, \{a, b, c\}, R, S \rangle$ with
    \[
        R = \begin{Bmatrix*}[l]
               S \to abc, &S \to aSBc, \\
               cB \to Bc, &bB \to bb
        \end{Bmatrix*}
    \]
    It generates the language $a^{n}b^{n}c^{n}$ for $n \in \mathbb{N}_{1}$ and is noncontracting.
\end{exmp}

The corresponding formalism for these languages are the linearly bounded nondeterministic Turing machines which can only write on the tape cells that contained a non-blank symbol.
This and an equivalent extension of Second-Order logic will be proven in~\cref{subsec:des-context-sensitive-languages}.