%! suppress = UnresolvedReference
%! suppress = MissingImport
\chapter{Personal Contribution}\label{ch:personal-contribution}

In this chapter, multiple tries at searches for new first order logics and other related concepts are presented.
The range of success as well as the range of the concrete themes are broad.
I did not find a fundamentally new result about the characterization of context-sensitive languages using first order logic, but managed to prove that various approaches could not work.
Further, I also lowered some upper bounds for simulating alternating Turing machines using iterative logic.
Using a restricted form of iterative logic, I could lower the bounds for an iterative simulation of a nondeterministic Turing Machine.

\section{Direct Transformation}\label{sec:direct-transformation}

Similar to Immerman in~\cite{descriptive-complexity}, we will use extended variables to model second order variables in first order logic.
This will then directly give us a characterization of NSPACE$[s(n)]$ without requiring any new insights, as we can just use the same technique as for second order logic.

\begin{define}[Extended Variable]
    The logic FO-VAR$[1, s(n)]$ has two types of variables.
    One are the normal domain variables, which we will denote by lowercase characters, ranging from $0$ to $n - 1$.
    Further, a formula can also include extended variables, which we will denote by uppercase characters, ranging from $0$ to $2^{s(n)\log(n)} - 1$, and thus having $s(n)\log(n)$ bits.
    The extended variables can not appear as an input to any predicate variables and can only be used in quantification and as an argument to the BIT relation.
    Thus, we can query if a specific bit in the binary representation is on.
    For extended variables with more than $n$ bits, we can extend BIT to accept a tuple of domain variables encoding the position.
    This makes polynomial extended variables possible.
\end{define}

The extended variables in FO-VAR$[1, s(n)]$ have exactly the same capabilities as second order variables in second order logic, as we can query it at a position, but can not do anything else.
As we want to capture NSPACE$[s(n)]$, we will now prove that SO(TC, arity $k$) = FO-VAR$[1, n^k/\log(n)]$(TC).

\begin{proof}
    We show by induction on the structures that every formula has a very similar equivalent
    For both, we show by induction that we can write an equivalent formula using the other logic.

    Any atomic formula of SO(TC, arity $k$) which does not include any second-order variable is trivially writable in FO-VAR$[1, n^k/\log(n)]$(TC).
    An atom of the form $Y(\overline{x})$ can be written as BIT$(Y', \overline{x})$ for $Y'$ being an extended variable.
    We then understand this as $Y$ being true with the variables $\overline{x}$ exactly when BIT$(Y', \overline{x})$ is true.
    This always works as we have relations of at most arity $k$, and thus $\overline{x}$ will never represent any higher number.

    Using this, we then can induct.
    Conjunction, disjunction and negation do not change anything.
    When we quantify over a second-order variable, we can directly exchange this with quantifying over an extended variable, as by induction the subformulas without the quantification is equivalent and plugging in the new second order / extended variable will not change this.
    Taking a transitive closure can also be done by replacing all second order variables with extended variables.

    By induction, we then have that all formulas in either of the logics has an equivalent formula in the other logic.
\end{proof}

Using this equivalence and the proof in \cref{subsec:des-context-sensitive-languages}, we get that FO-VAR$[1, n^k/\log(n)]$(TC) describes exactly the context-sensitive languages, and thus have our first characterization in first order logic.


\section{Analogues to Proof for DSPACE}\label{sec:analogues-to-proof-for-dspace}

For DSPACE$[s(n)]$, there are multiple other characterizations in logic without using the transitive closure operator.

To understand the following, we first need to define the logic FO$[t(n)]$, which formalizes iterative definitions, and then VAR$[k]$ which restricts the number of variable but allows for unbounded FO iterations.

\begin{define}[{FO$[t(n)]$}]
    Let $Q_1, \dots, Q_n$ be a series of quantifiers, $s_1, \dots, s_n$ variables and $M_1 \dots, M_n$ be quantifier-free formulas.
    Then a quantifier block is $QB = (Q_{1}s_{1}.M_{n})\dots(Q_{n}s_{n}.M_{n})$.
    Here, for a universal quantifier $(\forall s.M)\varphi \equiv \forall s (M \to \varphi)$.
    Also, for an existential quantifier $(\exists s.M)\varphi \equiv \exists s(M \land \varphi)$.
    Both of these effectively mean that we restrict the quantifiers to range only over the elements that satisfy $M$.
    Then, a formula of FO$[t(n)]$ is of the form
    \[
        \left([QB]^{t(n)}M_{0}\right)(\overline{c} / \overline{s})
    \]
    where $M_0$ is a quantifier-free formula, $\overline{c} = c_1, \dots, c_n$ is a tuple of constants and $\overline{s} = s_1, \dots, s_n$ are the variables occurring in the quantifier block.
    Also, $(\overline{c} / \overline{s})$ means that in the beginning, we set $s_1 \coloneqq c_n, \dots, s_n \coloneqq c_n$ and $[QB]^{t(n)}$ means $QB$ literally repeated $t(n)$ times.
    The truth values of these formulas for a specific structure are defined by iterating the quantifier block $t(|\mathcal{A}|)$ times.
\end{define}
So now we have a formalism for iterative procedures.

If we restrict the number of variables such that all $s_i$ need to be in $\{x_1, \dots, x_k \}$, apart from some boolean variables (variables which can only be $0$ or $1$), we get FO-VAR$[t(n), k]$.
Additionally, we define
\[
    \text{VAR}[k] = \bigcup_{c = 1}^{\infty}\text{FO-VAR}[2^{cn^k}, k]
\]
This is the same as saying that we have unbounded iterations, as after at most $2^{cn^k}$ the truth values of the formula will loop.
The $c$ depends on the number of boolean variables included.

Now, we are ready to look at DSPACE\@.
For DSPACE, we then have
\[
    \text{DSPACE}[n^k] = \text{VAR}[k + 1]
\]
A proof of this can be found in~\cite{descriptive-complexity}.
In the main part of the proof, a construction is made to simulate a DSPACE Turing machine using VAR$[k + 1]$.
There, the relation $C_{t}(\overline{x}, \overline{b})$ is inductively defined to mean that at time $t$, the character on the tape at position $\overline{x}$ is the one coded by $\overline{b}$, where $\overline{b}$ is a tuple of boolean variables.
Because the Turing machine we are contemplating is deterministic, this character is uniquely determined.
Further, it only depends on the previous characters at positions $\overline{x} - 1, \overline{x}$ and $\overline{x} + 1$, as we include the head position and state in the characters.
So this makes it possible for every position to go back in time and find out if we get to an ending state after $n^k$ steps.

If we want to extend this to nondeterministic Turing machines using $C_{t}(\overline{x}, \overline{b}) \equiv $ the character at position $\overline{x}$ \emph{can} be $\overline{b}$ at time $t$, we run into problems.
As we don't have the guarantee that the computation is deterministic, we can not say any more that we depend on the $C_{t - 1}(\overline{x}, \overline{b})$ only.
Doing this would mean that impossible states could be reached, and thus we would have false positives.
One way to fix this is by remembering the nondeterministic choices we made in the previous steps.
In the worst case, this would take $\mathcal{O}(2^{cn^k})$ additional bits.
But we already know by Savitch's Theorem (\cref{subsec:nspacesubsetdspacesquared}) and the equivalence for DSPACE that we only need $n \cdot (k + 2)$ bits to represent a NSPACE$[n^k]$ computation.

More generally, any proof which would show that NSPACE$[n^k]$ can be expressed in VAR$[r(n)]$, where VAR$[r(n)]$ is the generalization of VAR$[k]$ which means that a total of $r(n) + \mathcal{O}(1)$ bits are allowed, with $n \cdot (k + 1) \leq r(n) < n \cdot (k + 2)$ would be an improvement on Savitch's Theorem.
That is because the proof for DSPACE$[n^k]$ can easily be extended to more general polynomial functions, Immerman did this in~\cite{Immerman1999}.
Actually, this is a two-way relationship: if Savitch's Theorem can be improved, we can describe NSPACE with less than $k + 2$ variables and unbounded iterations.

\section{Mixing iterations and transitive closure}\label{sec:mixing-iterations-and-transitive-closure}

One question that came up during the process of finding a logic which is smaller than \[\text{FO-VAR}[s(n), s(n)/\log(n)]\] but still captures NSPACE$[s(n)]$.
This led to the idea of mixing up iterative procedures with the transitive closure operator.
I will now show that this approach will not help much and any restriction done this way would be mean that there exists a restriction using only iterative procedures that also contains NSPACE$[s(n)]$.

The first is surrounding a formula in FO-VAR$[t(n), r(n)/\log(n)]$ with a TC operator using variables of size $r(n)$.
For this to contain NSPACE$[s(n)]$, we need for any formula of the form $(\text{TC}_{a, b}\varphi)(c, d)$ that there exists a quantifier block, a formula $\phi$ and some constants $\overline{e}, f, g$ such that
\[
    \left(\text{TC}_{a, b}\left([QB]^{t(n)}\phi(\overline{e}/\overline{s})\right)\right)(f, g) \equiv (\text{TC}_{a, b}\varphi)(c, d)
\]
We know that we can simulate any TC formula with variables of size $r(n)$ using $r(n)$ iterations of a quantifier block.
Thus, we can rewrite the formula as
\[
    \left(\text{TC}_{a, b}\left([QB]^{t(n)}\phi(\overline{e}/\overline{s})\right)\right)(f, g) \equiv [QB_1]^{r(n)}[QB_2]^{t(n)}\phi(\overline{e}/\overline{s}, c/a, d/b)
\]
The two quantifier blocks can then be merged into one by additionally maintaining a counter variable of size $\log(r(n))$ so that the quantifier block acts as the first one would during the first $r(n)$ round and then acts like the other one.

The other case where we write the TC formula after the quantifier block is similar, then we have
\[
    \left([QB]^{t(n)}\left(\text{TC}_{a, b}\phi\right)(f, g)\right)(\overline{e}/\overline{s}) \equiv (\text{TC}_{a, b}\varphi)(c, d)
\]
For $c \cdot r(n) > \log(t(n))$ with some fixed $c$, we can do the same counting trick.
As a $t(n) > 2^{cr(n)}$ does not add any expressive power, we can assume that this is true.

Thus, in both cases, we have a formula in FO-VAR$[r(n) + t(n), r(n)/\log(n)]$.
Now, there are multiple cases
\begin{description}
    \setlength\itemsep{0.2em}
    \item[$r(n) \leq t(n)$]  Then, FO-VAR$[r(n) + t(n), r(n)/\log(n)] =$ FO-VAR$[t(n), r(n)/\log(n)]$.
    This is only interesting in the case where $r(n) < s(n)$
    \item[$r(n) > t(n)$] Then, FO-VAR$[r(n) + t(n), r(n)/\log(n)] =$ FO-VAR$[r(n), r(n)/\log(n)]$.
    This is again only interesting when $r(n) < s(n)$.
\end{description}

We thus get that anything interesting in this case happens only when we have less variable bits than $s(n)$.
Using Savitch's Theorem once more, we also get that $r(n) > \sqrt{n}$.
Another interesting result is that Savitch's Theorem can be improved for some possible results as
\[
    \text{FO-VAR}[t(n), r(n)/\log(n)] \subset \text{DSPACE}[t(n)r(n)]
\]
which would be smaller than $s(n)^2$ in some of these cases.
The same method also means that $t(n)r(n) \geq s(n)$ because of Savitch's Theorem and the Space Hierarchy theorem (\cref{subsec:space-hierarchy-theorem}).
As this is an open problem since 50 years, this seems to be a very difficult endeavour.

\section{Restricting universal quantification}\label{sec:restricting-universal-quantification}

One further approach that I attempted was restricting universal quantification in the FO-VAR formulas, which I called FO$\exists$-VAR\@.
In FO$\exists$-VAR, universal quantification is only allowed over boolean variables.
We will denote the boolean variables by $b_j$.
Further, the requirement of the $M_i$ to be quantifier-free is dropped.
This step was motivated by the fact that nondeterministic Turing machines in essence capture existential quantification.

A similar idea to the one in Savitch's Theorem, guessing the middle of the path and checking both shorter sides.
A formula in FO$\exists$-VAR$[s(n), s(n)/\log(n)]$ which is equivalent to a formula in FO-VAR$[1, s(n)/\log(n)]$ of the form $\left( TC_{\overline{X}, \overline{Y}}\varphi \right)(\overline{C}, \overline{D})$ is
\[
    \begin{aligned}
        QB \equiv~& (\forall b_{1}.M_{1})(\exists\overline{Z}) (\forall b_{2})(\exists \overline{A}, \overline{B}.M_{2})(\exists\overline{X}, \overline{Y}.M_{3}) \\
        M_{1} \equiv~& \neg(\forall \overline{z} (\text{BIT}(\overline{X}, \overline{z}) \leftrightarrow \text{BIT}(\overline{Y}, \overline{z})) \lor \varphi(\overline{X}, \overline{Y})) \\
        M_{2} \equiv~&(b_{2} \land \forall \overline{z} (\text{BIT}(\overline{X}, \overline{z}) \leftrightarrow \text{BIT}(\overline{A}, \overline{z}))\land \forall \overline{z} (\text{BIT}(\overline{B}, \overline{z}) \leftrightarrow \text{BIT}(\overline{Z}, \overline{z}))) \lor \\
        &(\neg b_{2} \land \forall \overline{z} (\text{BIT}(\overline{Z}, \overline{z}) \leftrightarrow \text{BIT}(\overline{A}, \overline{z}))\land \forall \overline{z} (\text{BIT}(\overline{B}, \overline{z}) \leftrightarrow \text{BIT}(\overline{Y}, \overline{z}))) \\
        M_{3} \equiv~&\forall \overline{z} (\text{BIT}(\overline{X}, \overline{z}) \leftrightarrow \text{BIT}(\overline{A}, \overline{z}))\land \forall \overline{z} (\text{BIT}(\overline{B}, \overline{z}) \leftrightarrow \text{BIT}(\overline{Y}, \overline{z}))
    \end{aligned}
\]
and finally
\[
    [QB]^{cs(n)}(false)(\overline{C} / \overline{X}, \overline{D} / \overline{Y})
\]
for some $c$.
This formula needs some explanation.
We let $M_1$ be the breaking condition, being false whenever either $\overline{X}$ and $\overline{Y}$ are the same or connected directly.
So in $QB$, the first quantification means that we break with true whenever we have a connection, as when this happens, we quantify over the empty set, which is defined as true.
After this, a middle configuration $\overline{Z}$ is guessed, and both sides $b_2$ are checked.
In $M_2$, we then check that $\overline{A}$ and $\overline{B}$ are the new endpoints which are defined by $b_2$ and $\overline{X}, \overline{Z}, \overline{Y}$.
After this, we copy $\overline{A}$ to $\overline{X}$ and $\overline{B}$ to $\overline{Y}$ in $M_3$.
When iterating this we guess a path from $\overline{C}$ to $\overline{D}$, checking every connection between adjacent states.

More generally, for any function $r(n) \leq 2^{cs(n)}$, we can define a formula in \[\text{FO$\forall, \exists$-VAR$[s(n)/\log(r(n)), \log(r(n)), s(n)r(n)/\log(n)]$}\]
Here, we define FO$\forall, \exists$-VAR$[t(n), f(n), s(n)]$ to contain all formulas which have $t(n)$ iterations, extended variables of $f(n)$ bits which can be universally quantified and $s(n)\log(n)$ bit extended variables which can be used in existential quantification.
These formulas are very similar to the one defined for FO$\exists$-VAR from above.
The only difference lies in the splitting.
Instead of splitting paths into two parts, we split them into $r(n)$ parts.
Thus, for a path of length $2^{cs(n)}$, we need \[\log_{r(n)}\left(2^{cs(n)}\right) = \frac{\log\left(2^{cs(n)}\right)}{\log(r(n))} = cs(n)/\log(r(n))\] iterations.
As for simulating this formula with a Turing machine, the product of the number of iterations and the size of the extended variables is important, we do not gain any tighter results from this.

\section{Alternating bounds}\label{sec:alternating-bounds}

In the proof of Savitch's Theorem, we use alternating Turing machines as an intermediate step for proving that NSPACE$[s(n)]$ is a subset of DSPACE$[s(n)^2]$.
We can also add another intermediate step using FO-VAR$[s(n), s(n)/\log(n)]$ with the method shown in \cref{sec:restricting-universal-quantification}.
It is also quite easy to simulate any formula in FO-VAR$[t(n), s(n)/\log(n)]$ with an alternating Turing machine in ATSR$[t(n)s(n), s(n), t(n)]$, where in this new class ATSR, we specify \emph{t}ime, \emph{s}pace and \emph{r}eversals.
With reversals, we mean the number of times we switch from universal states to existential states and back.
We do this by writing the current values of all variables during the iterated quantifier part and evaluating the quantifier-free FO formulas, which can be done efficiently.

We will now investigate two ways of simulating an ATSR$[t(n), s(n), r(n)]$ Turing machine using FO-VAR\@.

The first one is a straightforward simulation of each step of the computation.
For this, we encode the whole state of the Turing machines in a tuple of $s(n)$ bit extended variables, and always guess the next step.
Also, we assume without loss of generality that a predicate $existential(\overline{X})$ exists and that there exists exactly one accepting state, denoted by $\overline{E}$.
\[
    \begin{aligned}
        QB \equiv~&(\forall b.M_{1})(\exists\overline{A}.\varphi(\overline{X}, \overline{A}))(\forall \overline{B}.M_{2})(\exists \overline{X}. \forall \overline{z}(\text{BIT}(\overline{X}, \overline{z}) \leftrightarrow \text{BIT}(\overline{B}, \overline{z}))) \\
        M_{1} \equiv~&\neg\forall \overline{z}(\text{BIT}(\overline{X}, \overline{z}) \leftrightarrow \text{BIT}(\overline{E}, \overline{z})) \\
        M_{2} \equiv~& (existential(\overline{X}) \to \forall \overline{z}(\text{BIT}(\overline{A}, \overline{z}) \leftrightarrow \text{BIT}(\overline{B}, \overline{z}))) \land \varphi(\overline{X}, \overline{B})
    \end{aligned}
\]
with \[
         \left([QB]^{t(n)}(false)\right)(\overline{S} / \overline{X})
\]
This gives us a formula in FO-VAR$[t(n), s(n)/\log(n)]$ which simulates the procedures of an alternating Turing machine.
To simplify it, some $M_i$ are not quantifier-free.
These can be moved out in an equivalent way, but make the formula less readable.
The inner formulas work as follows:
The formula $QB$ starts of with checking if we already achieved our goal and the actual configuration is the accepting configuration using $M_1$.
Next, if we are not done yet, we first existentially guess the next configuration, restricting this quantification to only those configurations which are directly connected to the actual one.
In $M_2$ we either retain this existentially guessed next state if we are in an existential state (thus effectively doing nothing) or ignore the existentially quantified state and just quantify universally over all states which are connected to the current one.
The last thing we do is copying $\overline{B}$ to $\overline{X}$, preparing it to be the new start of the path.

By combining the above techniques for switching between universal and existential quantification with the path-halving method from Savitch's Theorem, we get an even stronger result.

On a high level, the plan is to do the following:
\begin{enumerate}
    \setlength\itemsep{0.2em}
    \item From the actual starting vertex, find all reachable vertices using only vertices which have the same type as the starting vertex.
    \begin{enumerate}
        \item For existential states, we can use the normal technique of halving paths naively
        \item For universal states, we need to quantify for all ending vertices and then consider two cases
        \begin{enumerate}
            \item We claim that there is no path using only universal states going to this vertex.
            Then, we need to show that for each middle vertex, one of the two new paths still does not exist.
            \item We claim that a path exists.
            In this case, we can try to find a path normally.
        \end{enumerate}
    \end{enumerate}
    \item Repeat with all the reached vertices
\end{enumerate}

Before presenting the formula, we can first think of how much iterations we need to do.
Because of the halving trick, we use $\log(a)$ iterations for a path of length $a$ with only one quantifier type.
To get an upper bound on the total number of iterations, we can use Jensen's inequality (\cite{inequalities-math-oly}, p.28).
We then get
\[
    \frac{\sum_{j = 0}^{r(n)}\log(a_{j})}{r(n)} \leq \log\left( \frac{\sum_{j= 0}^{r(n)}a_{j}}{r(n)} \right) = \log\left( \frac{t(n)}{r(n)} \right)
\]
because of the condition that $\sum_{j= 0}^{r(n)}a_{j} = t(n)$.
Multiplying this with $r(n)$, we get that a path can require a maximum of $r(n)\log\left( \frac{t(n)}{r(n)} \right)$ iterations.
Thus, the formula is in FO-VAR$\left[ r(n)\log\left( t(n)/r(n) \right), s(n)/\log(n) \right]$

The formula is then as follows:
\[
    \begin{aligned}
        QB \equiv&~(\forall b_{0}.M_{1})(\exists b_{0}.N_{1})(\exists b_{1}.M_{2})(\exists Z_{e}.M_{3})(\forall Z.N_{2})\\
        &~(\exists b_{2e})(\forall b_{2}.N_{3})(\exists A, B.M_{4})(\forall S, E.M_{5})(\exists A, B.M_{6})(\exists I, X.M_{7})(\exists b_{0}.N_{4})(\exists b_{path}.N_{5}) \\
        M_{1} \equiv&~b_{path} \to \neg(I = Y \land (S = E \lor \varphi(S, E))) \\
        N_{1} \equiv&~\neg b_{path} \to \neg(S = E \lor \varphi(S, E)) \\
        M_{2} \equiv&~\neg b_{1} \leftrightarrow (S = E \lor \varphi(S, E)) \\
        M_{3} \equiv&~existential(Z_{e}) \leftrightarrow existential(X)\\
        N_{2} \equiv&~(b_{path} \to Z = Z_{e}) \land (existential(Z) \leftrightarrow existential(X))\\
        N_{3} \equiv&~ \neg b_{path} \to b_{2} = b_{2e}\\
        M_{4} \equiv&~(b_{1} \land ((\neg b_{2} \land A = S  \land B = Z) \lor (b_{2} \land A = Z \land B = E))) \lor \\
        &~(\neg b_{1} \land  A = I \land (B = Y \lor (existential(B) \leftrightarrow \neg existential(I)))) \\
        M_{5} \equiv&~S = A \land ((( b_{1} \lor existential(S)) \land E = B) \lor \\
        &~(\neg( b_{1} \lor existential(S)) \land (E = Y \lor (existential(E)\leftrightarrow \neg existential(S))))) \\
        M_{6} \equiv&~(\neg b_{1}  \land S = A \land E = B) \lor (b_{1} \land X = A \land I = B)\\
        M_{7} \equiv&~X = A \land I = B \\
        N_{4} \equiv&~b_{0} = b_{path} \\
        N_{5} \equiv&~(b_{1} \land b_{path} = b_{0}) \lor (\neg b_{1} \land (existential(X) \to b_{path}))
    \end{aligned}
\]
and $\left([QB]^{r(n)\log(t(n)/r(n))}(\neg b_{path})\right)(true / b_{path}, AS / S, AS / X, AS /I, AS /S, AS / E, AE / Y)$ being the final formula.
First, we will look at the meaning of the variables:
\begin{description}
    \setlength\itemsep{0.2em}
    \item[$Y$:] the accepting configuration
    \item[$X$:] the actual starting configuration from which we started the search
    \item[$I$:] the vertex for which we are checking that a connection from $X$ exists
    \item[$S$:] the start of the path we are checking right now
    \item[$E$:] the end of the path we are checking right now
    \item[$Z, Z_{e}$:] the guessed middle configuration of a path from $S$ to $E$
    \item[$A, B, b_{0}$:] variables used for copying or as dummies
    \item[$b_{path}$:] whether we are trying to show that there is a path or that there is no path from $S$ to $E$
    \item[$b_{1}$:] remember whether $S$ and $E$ are connected
    \item[$b_{2}, b_{2e}$:] which half of the $S \to Z \to E$ path should be checked
\end{description}
As this formula is quite intricate, it is proposed to read it in four goes.
\begin{enumerate}
    \item First, we look at the formula in the easiest case: We are still trying to find a path from $X$ to $I$ using $S$ and $E$, which are not connected.
    In this case, we have $b_{path}$ and $b_1$ as true.
    Then, $QB$ works like this:
    First, in $M_1$, we check that we are not done, which we aren't as $S$ and $E$ are not connected.
    As $b_{path}$ is true, $N_1$ does not affect anything.
    In $M_2$, $b_1$ is set to true.
    Then we guess a middle configuration between $S$ and $E$ which has the same type as $X$ in $M_3$.
    $N_2$ just copies $Z_e$ into $Z$.
    Next, we choose a side of the path.
    As $b_{path}$ is true, this is done universally, because $N_3$ ignores the choice that was made with $b_{2e}$.
    In this case, $M_4$ copies the relevant new starting and ending points to $A$ and $B$.
    Because $b_1$ is true, we then copy $A$ and $B$ to $S$ and $E$ in $M_5$.
    When combining $M_6$ and $M_7$, we just retain $X$ and $I$ to make them stay the same using $A$ and $B$.
    The same happens with $b_{path}$ using $N_4$, $N_5$ and $b_0$.
    So in the end, we get a new configuration with a guessed middle configuration replacing either the former ending or starting point.
    If no path exists, this will continue until the formula $\neg b_{path}$ marks this branch as false.

    \item The second option we look at is when we do not want a path to exist.
    In that case, we have $\neg b_{path}$.
    Because of this, $M_1$ does not have any effect.
    In $N_1$, we check that we did not find any connection after all, and if we did find one, this logical branch will be false because of the existential quantification.
    If we get $N_1$ is true, we get on to $M_2$, which will establish $b_1$.
    The formula $N_2$ completely ignores $M_3$, which thus has no effect.
    $N_2$ itself then universally quantifies over all middle vertices $Z$ which could lie on a path between $S$ and $E$.
    The next two quantifiers have the effect of quantifying existentially which half of $S \to Z \to E$ is not connected.
    This half must exist as otherwise a path from $S$ to $E$ exists, which we want to be false in this case.
    Because we again have $b_1$ as true, $M_4$ will copy the relevant part of the path to $A$ and $B$.
    These are then copied back to $S$ and $E$ in $M_5$.
    $M6$, $M_7$, $N_4$ and $N_5$ do the same as in the connection case, which was resetting $S$, $E$, $X$ and $I$ to the same value.
    If effectively no path exists, we will continue doing this until we hit $\neg b_{path}$.
    At this point, the branch will then be true, as effectively, no path exists from $X$ to $I$ by making these choices.

    \item The third possibility we need to consider is that we are presently trying to do a path from $X$ to $I$ and that we succeed in finding a connection between $S$ and $E$.
    In this case, we have $b_{path}$ and $\neg b_1$.
    In this case, we look at what happens when the current component, and thus $X$, is universal.
    In $M_1$, if $I = Y$, we are done, as we reached the accepting configuration.
    Otherwise, we can again ignore $N_1$, and $M_2$ will set $b_1$ to false.
    We can ignore the quantification for $Z$ and $b_2$ as they will not be used in this iteration of the formula.
    In $M_4$, $A$ and $B$ are guessed such that $A$ is the new starting vertex, which was the ending vertex before, and $B$ is either the ending vertex or a vertex of the other type.
    Then, $M_5$ copies $A$ to $S$, marking it as the starting vertex.
    Further, because we changed quantification type, we have that a valid $S$ must now be existential.
    Thus, we also copy $B$ too $E$ directly.
    After that, we copy back $S$ to $A$ and $E$ to $B$ in $M_6$, for them to set $X$ and $I$ accordingly.
    The last change happens in $N_{5}$, where we set $b_{path}$ to be true.
    Thus, the state is set for a new block of existential states.

    \item The last option is similar to the third one, with the difference that the actual state $X$ is existential.
    In this case, we have $b_{path}$ and $\neg b_1$.
    In $M_1$, if $I = Y$, we are done, as we reached the accepting configuration.
    Otherwise, we can again ignore $N_1$, and $M_2$ will set $b_1$ to false.
    We can ignore the quantification for $Z$ and $b_2$ as they will not be used in this iteration of the formula.
    In $M_4$, $A$ and $B$ are guessed such that $A$ is the new starting vertex, which was the ending vertex before, and $B$, which will be ignored later, is either the ending vertex or a vertex of the other type.
    Then, $M_5$ copies $A$ to $S$, marking it as the starting vertex.
    Further, because we changed quantification type, we have that a valid $S$ must now be existential.
    Thus, we quantify universally over all vertices which are either the ending vertex or have the other type.
    After that, we copy back $S$ to $A$ and $E$ to $B$ in $M_6$, for them to set $X$ and $I$ accordingly.
    The last change happens in $N_{5}$, where we quantify existentially over both possibilities we set for that new ending vertex, having a path, or not.
    Thus, the state is set for a new block of universal states.
\end{enumerate}
The complete formula sets the starting conditions to be such that we are trying to find a path with $b_{path} = true$, and that all of $X, S, E$ and $I$ are set to the staring configuration $AS$.
The ending $Y$ is set to the desired ending $AE$.
This starting configuration will trigger either case three or four and make the first cycle possible.

These results allow for enclosing the ATSR class quite with only a logarithmic overhead between two FO-VAR classes.
\[
    \text{FO-VAR}\left[ a(n), s(n)/\log n \right] \subseteq \text{ATSR}[a(n)s(n), s(n), a(n)] \subseteq \text{FO-VAR}\left[ a(n)\log(s(n)), s(n)/\log n \right]
\]